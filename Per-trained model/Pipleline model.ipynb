{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5a1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab74602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to C:\\Users\\researcher\\.huggingface\\token\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8125c4d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a301be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cc7ed69c414570b17ad7135db98f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3140\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 674\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 673\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"HFFErica/Sentiment_Analysis_FinalBalanced\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34709958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae748ce71ca64624b9bf4cdb4f3d95a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b198527dc543679c126f17552c102b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92507330df9347ddb8c31095f53fe121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4608a4fb1a4cc38b71a6eff23f4610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff2aaf37d034c0db3bb14977b753e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a3f06e44464bb2a9d5af0c6bfe958e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bf0979a9934534a72f643763f499ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c3f82306bc46459d230a5c96810a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedf10ccf21f4f9e945f8ecbe5f99908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8de70a90a20401582f030cdfb5c3266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87792ac93f2a4325a1d90c34e66fade1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9a658ff6514f95b5bf7bdd069643af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb1829f779c48f8bf7990fc2acff1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b989f56deb464a608169dfe3c6c178b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82\n",
      "Found cached dataset csv (C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcaa0cbedd34474a73a03cc5f369925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=15)\n",
    "splits = folds.split(np.zeros(dataset[\"train\"].num_rows), dataset[\"train\"][\"label\"])\n",
    "\n",
    "for train_idxs, val_idxs in splits:\n",
    "    dataset = load_dataset(\"HFFErica/Sentiment_Analysis_FinalBalanced\")\n",
    "    dataset[\"test\"] = dataset[\"test\"]\n",
    "    dataset[\"validation\"] = dataset[\"train\"].select(val_idxs)\n",
    "    dataset[\"train\"] = dataset[\"train\"].select(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1acb9fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-459aa64e154cb94e.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-2fe4fd8d11515d7a.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-487452558d32867e.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-459aa64e154cb94e.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-2fe4fd8d11515d7a.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-487452558d32867e.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-459aa64e154cb94e.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-2fe4fd8d11515d7a.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-487452558d32867e.arrow\n"
     ]
    }
   ],
   "source": [
    "features = dataset[\"train\"].features.copy()\n",
    "features[\"label\"] = ClassLabel(names=['negative', 'neutral', 'positive'])\n",
    "def adjust_labels(batch):\n",
    "    batch[\"label\"] = [sentiment  for sentiment  in batch[\"label\"]]\n",
    "    return batch\n",
    "label_dataset = dataset.map(adjust_labels, batched=True, features=features)\n",
    "\n",
    "features = dataset[\"validation\"].features.copy()\n",
    "features[\"label\"] = ClassLabel(names=['negative', 'neutral', 'positive'])\n",
    "def adjust_labels(batch):\n",
    "    batch[\"label\"] = [sentiment  for sentiment  in batch[\"label\"]]\n",
    "    return batch\n",
    "label_dataset = dataset.map(adjust_labels, batched=True, features=features)\n",
    "\n",
    "features = dataset[\"test\"].features.copy()\n",
    "features[\"label\"] = ClassLabel(names=['negative', 'neutral', 'positive'])\n",
    "def adjust_labels(batch):\n",
    "    batch[\"label\"] = [sentiment  for sentiment  in batch[\"label\"]]\n",
    "    return batch\n",
    "label_dataset = dataset.map(adjust_labels, batched=True, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405c8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = label_dataset['train']\n",
    "validation_dataset = label_dataset['validation']\n",
    "test_dataset = label_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22a10f",
   "metadata": {},
   "source": [
    "# Model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f327d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-c79b357875acba22.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-caa705ff656ff781.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-2dc5014879c6488b.arrow\n"
     ]
    }
   ],
   "source": [
    "training_dataset = training_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "validation_dataset = validation_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "test_dataset = test_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45ef39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = 'prajjwal1/bert-tiny'\n",
    "model_id=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "\n",
    "label2id = {\"positive\": 2, \"neutral\": 1,\"negative\":0}\n",
    "id2label = {\"positive\": 2, \"neutral\": 1,\"negative\":0}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, \n",
    "            num_labels=training_dataset.features[\"label\"].num_classes,label2id=label2id,id2label=id2label)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcc40daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-a1b2bd54a3ebb26c.arrow\n",
      "Loading cached processed dataset at C:/Users/researcher/.cache/huggingface/datasets/HFFErica___csv/HFFErica--Sentiment_Analysis_FinalBalanced-bf72ccc2438e6a82/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-3f21103fb6c1fb05.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fab342a6c8d4254bbea239e5f85d904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 256\n",
    "training_dataset = training_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "validation_dataset = validation_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "test_dataset = test_dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac6f928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.set_format(type='torch', columns=['input_ids',  'attention_mask', 'labels'])\n",
    "validation_dataset.set_format(type='torch', columns=['input_ids',  'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids',  'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e18d11",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3690c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b590d36f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2931\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 920\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mericatong-com\u001b[0m (\u001b[33mericatong\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Projects\\Jupyter\\FinalPilotStudy\\Report_generate\\sentiment analysis\\wandb\\run-20240508_112100-rk9jv7vt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ericatong/huggingface/runs/rk9jv7vt\" target=\"_blank\">./sentimentbinaryresults</a></strong> to <a href=\"https://wandb.ai/ericatong/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [920/920 04:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.005800</td>\n",
       "      <td>0.871458</td>\n",
       "      <td>0.612440</td>\n",
       "      <td>0.613830</td>\n",
       "      <td>0.633296</td>\n",
       "      <td>0.609288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>0.797144</td>\n",
       "      <td>0.655502</td>\n",
       "      <td>0.656784</td>\n",
       "      <td>0.677208</td>\n",
       "      <td>0.652310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.607300</td>\n",
       "      <td>0.799574</td>\n",
       "      <td>0.650718</td>\n",
       "      <td>0.651264</td>\n",
       "      <td>0.663448</td>\n",
       "      <td>0.647871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.579100</td>\n",
       "      <td>0.814388</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>0.678217</td>\n",
       "      <td>0.661054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.799648</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.662793</td>\n",
       "      <td>0.669312</td>\n",
       "      <td>0.661633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.903633</td>\n",
       "      <td>0.669856</td>\n",
       "      <td>0.666288</td>\n",
       "      <td>0.673969</td>\n",
       "      <td>0.665811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.338400</td>\n",
       "      <td>0.939155</td>\n",
       "      <td>0.669856</td>\n",
       "      <td>0.667235</td>\n",
       "      <td>0.669553</td>\n",
       "      <td>0.666841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.290800</td>\n",
       "      <td>0.970429</td>\n",
       "      <td>0.688995</td>\n",
       "      <td>0.684563</td>\n",
       "      <td>0.690481</td>\n",
       "      <td>0.684844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>1.027508</td>\n",
       "      <td>0.665072</td>\n",
       "      <td>0.662518</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>0.662402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./sentimentbinaryresults\\checkpoint-500\n",
      "Configuration saved in ./sentimentbinaryresults\\checkpoint-500\\config.json\n",
      "Model weights saved in ./sentimentbinaryresults\\checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 209\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./sentimentbinaryresults\\checkpoint-500 (score: 0.7996482849121094).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./sentimentbinaryresults',          # output directory\n",
    "    learning_rate=1.7678464639846776e-05,\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=100,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    load_best_model_at_end=True,\n",
    "    eval_steps=100,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=training_dataset,         # training dataset\n",
    "    eval_dataset=validation_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_out = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ef0822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/sa_model\n",
      "Configuration saved in ./models/sa_model\\config.json\n",
      "Model weights saved in ./models/sa_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./models/sa_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cc273",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54142d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertConfig, BertModel\n",
    "# # if model is on hugging face Hub\n",
    "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# # from local folder\n",
    "# model = BertModel.from_pretrained(\"./test/saved_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb60455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./models/sa_model/config.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'negative'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/sa_model/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:434\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m hub_kwargs \u001b[38;5;241m=\u001b[39m {name: kwargs\u001b[38;5;241m.\u001b[39mpop(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m hub_kwargs_names \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m--> 434\u001b[0m     config, kwargs \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    435\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    436\u001b[0m         return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    437\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    440\u001b[0m     )\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:791\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    790\u001b[0m     config_class \u001b[38;5;241m=\u001b[39m CONFIG_MAPPING[config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\configuration_utils.py:681\u001b[0m, in \u001b[0;36mPretrainedConfig.from_dict\u001b[1;34m(cls, config_dict, **kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    679\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 681\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruned_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    684\u001b[0m     config\u001b[38;5;241m.\u001b[39mpruned_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((\u001b[38;5;28mint\u001b[39m(key), value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mpruned_heads\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\distilbert\\configuration_distilbert.py:139\u001b[0m, in \u001b[0;36mDistilBertConfig.__init__\u001b[1;34m(self, vocab_size, max_position_embeddings, sinusoidal_pos_embds, n_layers, n_heads, dim, hidden_dim, dropout, attention_dropout, activation, initializer_range, qa_dropout, seq_classif_dropout, pad_token_id, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqa_dropout \u001b[38;5;241m=\u001b[39m qa_dropout\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_classif_dropout \u001b[38;5;241m=\u001b[39m seq_classif_dropout\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, pad_token_id\u001b[38;5;241m=\u001b[39mpad_token_id)\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\configuration_utils.py:317\u001b[0m, in \u001b[0;36mPretrainedConfig.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2label) \u001b[38;5;241m!=\u001b[39m num_labels:\n\u001b[0;32m    313\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    314\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed along `num_labels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` with an incompatible id to label map: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    315\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. The number of labels wil be overwritten to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m         )\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid2label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# Keys are always strings in JSON so convert ids to int here.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\configuration_utils.py:317\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2label) \u001b[38;5;241m!=\u001b[39m num_labels:\n\u001b[0;32m    313\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    314\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed along `num_labels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` with an incompatible id to label map: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    315\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. The number of labels wil be overwritten to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m         )\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m, value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2label\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# Keys are always strings in JSON so convert ids to int here.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'negative'"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./models/sa_model/\")\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2046517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentence</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>readability</th>\n",
       "      <th>preprocessed_reviews</th>\n",
       "      <th>wordtoken</th>\n",
       "      <th>correctmapping</th>\n",
       "      <th>ngrams_reviews</th>\n",
       "      <th>ngrams_token</th>\n",
       "      <th>lda_reviews</th>\n",
       "      <th>lda_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275850</td>\n",
       "      <td>1</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>this be my review prior to the update nothis g...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>['this', 'be', 'my', 'review', 'prior', 'to', ...</td>\n",
       "      <td>this be my review prior to the update nothin g...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "      <td>review prior update nothin fail miserably anno...</td>\n",
       "      <td>['review', 'prior', 'update', 'nothin', 'fail'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275850</td>\n",
       "      <td>2</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>When the game first came out it had over 200,0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>['when', 'the', 'game', 'first', 'come', 'out'...</td>\n",
       "      <td>when the game first come out it have over play...</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "      <td>first come player one point mear</td>\n",
       "      <td>['first', 'player', 'one', 'point', 'mear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275850</td>\n",
       "      <td>3</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>If that doesn't prove this game is the biggest...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>['if', 'that', 'do', 'not', 'prove', 'this', '...</td>\n",
       "      <td>if that do not prove this game be the big scam...</td>\n",
       "      <td>['prove', 'this_game', 'big', 'scam', 'know']</td>\n",
       "      <td>prove big scam know</td>\n",
       "      <td>['prove', 'big', 'scam', 'know']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275850</td>\n",
       "      <td>4</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>The devs completely lied about countless featu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>['the', 'developer', 'completely', 'lie', 'abo...</td>\n",
       "      <td>the developer completely lie about countless f...</td>\n",
       "      <td>['the_developer', 'completely', 'lie_about', '...</td>\n",
       "      <td>developer completely lie countless feature meant</td>\n",
       "      <td>['developer', 'completely', 'lie', 'countless'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275850</td>\n",
       "      <td>5</td>\n",
       "      <td>No Man's Sky</td>\n",
       "      <td>This was my review prior to the 1.1 update ___...</td>\n",
       "      <td>______________________________________________...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>i clearly have very strong feel about the game...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>['clearly', 'have', 'very', 'strong', 'feel', ...</td>\n",
       "      <td>clearly have very strong feel about the game a...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play', 'hour', ...</td>\n",
       "      <td>clearly strong feel play hour hello games rele...</td>\n",
       "      <td>['clearly', 'strong', 'feel', 'play_hour', 'he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  index          name  \\\n",
       "0  275850      1  No Man's Sky   \n",
       "1  275850      2  No Man's Sky   \n",
       "2  275850      3  No Man's Sky   \n",
       "3  275850      4  No Man's Sky   \n",
       "4  275850      5  No Man's Sky   \n",
       "\n",
       "                                             content  \\\n",
       "0  This was my review prior to the 1.1 update ___...   \n",
       "1  This was my review prior to the 1.1 update ___...   \n",
       "2  This was my review prior to the 1.1 update ___...   \n",
       "3  This was my review prior to the 1.1 update ___...   \n",
       "4  This was my review prior to the 1.1 update ___...   \n",
       "\n",
       "                                            sentence  review_score  \\\n",
       "0  This was my review prior to the 1.1 update ___...             1   \n",
       "1  When the game first came out it had over 200,0...             1   \n",
       "2  If that doesn't prove this game is the biggest...             1   \n",
       "3  The devs completely lied about countless featu...             1   \n",
       "4  ______________________________________________...             1   \n",
       "\n",
       "   review_votes  readability  \\\n",
       "0             1         17.6   \n",
       "1             1          6.5   \n",
       "2             1          5.6   \n",
       "3             1          8.7   \n",
       "4             1         29.1   \n",
       "\n",
       "                                preprocessed_reviews  \\\n",
       "0  this be my review prior to the update nothis g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  i clearly have very strong feel about the game...   \n",
       "\n",
       "                                           wordtoken  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      correctmapping  \\\n",
       "0  ['this', 'be', 'my', 'review', 'prior', 'to', ...   \n",
       "1  ['when', 'the', 'game', 'first', 'come', 'out'...   \n",
       "2  ['if', 'that', 'do', 'not', 'prove', 'this', '...   \n",
       "3  ['the', 'developer', 'completely', 'lie', 'abo...   \n",
       "4  ['clearly', 'have', 'very', 'strong', 'feel', ...   \n",
       "\n",
       "                                      ngrams_reviews  \\\n",
       "0  this be my review prior to the update nothin g...   \n",
       "1  when the game first come out it have over play...   \n",
       "2  if that do not prove this game be the big scam...   \n",
       "3  the developer completely lie about countless f...   \n",
       "4  clearly have very strong feel about the game a...   \n",
       "\n",
       "                                        ngrams_token  \\\n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...   \n",
       "1        ['first', 'player', 'one', 'point', 'mear']   \n",
       "2      ['prove', 'this_game', 'big', 'scam', 'know']   \n",
       "3  ['the_developer', 'completely', 'lie_about', '...   \n",
       "4  ['clearly', 'strong', 'feel', 'play', 'hour', ...   \n",
       "\n",
       "                                         lda_reviews  \\\n",
       "0  review prior update nothin fail miserably anno...   \n",
       "1                   first come player one point mear   \n",
       "2                                prove big scam know   \n",
       "3   developer completely lie countless feature meant   \n",
       "4  clearly strong feel play hour hello games rele...   \n",
       "\n",
       "                                           lda_token  \n",
       "0  ['review', 'prior', 'update', 'nothin', 'fail'...  \n",
       "1        ['first', 'player', 'one', 'point', 'mear']  \n",
       "2                   ['prove', 'big', 'scam', 'know']  \n",
       "3  ['developer', 'completely', 'lie', 'countless'...  \n",
       "4  ['clearly', 'strong', 'feel', 'play_hour', 'he...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_examples = pd.read_csv('D:\\Projects\\Jupyter\\Github Docs\\datasets\\preprocessed_word_correct_token.csv', encoding='utf-8')\n",
    "test_examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "969c94d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    this be my review prior to the update nothis g...\n",
       "1    when the game first come out it have over play...\n",
       "2    if that do not prove this game be the big scam...\n",
       "3    the developer completely lie about countless f...\n",
       "4    i clearly have very strong feel about the game...\n",
       "5    obviously the update do not add all the featur...\n",
       "6    it show that hello games s have start take a s...\n",
       "7    i really do enjoy the game when it first be re...\n",
       "8    it be very nice to see the developer go back t...\n",
       "9    thought about the update game mode the additon...\n",
       "Name: preprocessed_reviews, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=test_examples['preprocessed_reviews'][:10]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d9d9f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    }
   ],
   "source": [
    "results = classifier(df1.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae64448c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9011141061782837},\n",
       " {'label': 'negative', 'score': 0.3804549276828766},\n",
       " {'label': 'positive', 'score': 0.8604347109794617},\n",
       " {'label': 'positive', 'score': 0.6175441741943359},\n",
       " {'label': 'negative', 'score': 0.9381702542304993},\n",
       " {'label': 'negative', 'score': 0.9557508230209351},\n",
       " {'label': 'negative', 'score': 0.48926693201065063},\n",
       " {'label': 'negative', 'score': 0.9311621785163879},\n",
       " {'label': 'negative', 'score': 0.9220345616340637},\n",
       " {'label': 'negative', 'score': 0.9807441830635071}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "237.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
